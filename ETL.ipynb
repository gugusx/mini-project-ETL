{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c825a272-c020-4498-9f3e-aacf7085952b",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452fe8e-3433-4b97-9f04-1dd6f59f36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install sqlalchemy\n",
    "#!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a9824-2209-4100-9d66-ac3f2167c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.parse import quote_plus\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from config import oltp_conn_string\n",
    "from config import warehouse_conn_string\n",
    "from config import etl_config\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9756093-3979-4fca-a671-03404c9fb0ce",
   "metadata": {},
   "source": [
    "### Logging setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8c08d-ca85-4847-81f9-8d5d2ae759d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbaecb0-5cdd-498d-9e6a-8a2b28f44e55",
   "metadata": {},
   "source": [
    "### Setup connection from Source to Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d4700-1d39-4bd5-8fc7-dc447e83c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_connection(conn_params):\n",
    "    conn_str = f\"postgresql://{conn_params['user']}:{quote_plus(conn_params['password'])}@{conn_params['host']}:{conn_params['port']}/{conn_params['database']}\"\n",
    "    engine = create_engine(conn_str)\n",
    "    return engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd323c-46e0-4b28-b915-46139b1cd14b",
   "metadata": {},
   "source": [
    "### Validate the ETL configuration (config.py -> can be customize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2872d55-15fb-4e32-8e70-db9f8ce938e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_config(etl_config):\n",
    "    required_keys = ['source_table', 'query', 'destination_table', 'column_mapping']\n",
    "    for table_name, table_config in etl_config.items():\n",
    "        for key in required_keys:\n",
    "            if key not in table_config:\n",
    "                raise ValueError(f\"Missing {key} in config for table {table_name}\")\n",
    "    logging.info(\"Config validation passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31125604-2b1b-4e5c-8318-5c0e88934c6e",
   "metadata": {},
   "source": [
    "### Extract data from the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de401a03-3fb9-4ea8-8e88-0b9b079c7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(table_config):\n",
    "    try:\n",
    "        logging.info(f\"Extracting data from {table_config['source_table']}...\")\n",
    "        with db_connection(oltp_conn_string) as conn:\n",
    "            df = pd.read_sql(table_config[\"query\"], conn)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting data from {table_config['source_table']}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd7503-f2a7-4fae-a00d-910c41ae352c",
   "metadata": {},
   "source": [
    "### Transform the extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e675fb3-7973-49fa-b7ef-9715c930d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, table_config):\n",
    "    try:\n",
    "        logging.info(f\"Transforming data for {table_config['destination_table']}...\")\n",
    "        df.rename(columns=table_config[\"column_mapping\"], inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error transforming data for {table_config['destination_table']}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b42357-3912-46db-bad6-78f082376648",
   "metadata": {},
   "source": [
    "### Load the transformed data into the destination table, replacing the data without dropping the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa393192-d21d-4fa6-b67f-3666384e66b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "def load(df, table_config):\n",
    "    try:\n",
    "        logging.info(f\"Replacing data in {table_config['destination_table']}...\")\n",
    "\n",
    "        # Connect to the warehouse database (destination)\n",
    "        with db_connection(warehouse_conn_string) as conn:\n",
    "            # Step 1: Remove all rows + reset identity using text()\n",
    "            conn.execute(text(f\"TRUNCATE TABLE {table_config['destination_table']} RESTART IDENTITY CASCADE;\"))\n",
    "            conn.commit()\n",
    "\n",
    "            # Step 2: Insert the new records into the table\n",
    "            df.to_sql(\n",
    "                table_config[\"destination_table\"], \n",
    "                conn, \n",
    "                if_exists=\"append\",  # This will insert new data\n",
    "                index=False\n",
    "            )\n",
    "        \n",
    "        logging.info(f\"Data successfully loaded into {table_config['destination_table']}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error replacing data in {table_config['destination_table']}: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e52f4-b884-4c14-9655-7ea886b4af96",
   "metadata": {},
   "source": [
    "### Run full ETL process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55708b-1257-4115-aa5c-d3469cd927f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_etl():\n",
    "    try:\n",
    "        logging.info(\"Starting ETL Process...\")\n",
    "        validate_config(etl_config) \n",
    "        for table_name, table_config in etl_config.items():\n",
    "            df = extract(table_config)\n",
    "            df = transform(df, table_config)\n",
    "            load(df, table_config)\n",
    "        logging.info(\"ETL Process Completed Successfully!\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"ETL process failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4adf78-388a-4536-a577-182024caca33",
   "metadata": {},
   "source": [
    "### Run Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f65296-ae9e-4566-8870-fa03ec7125f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_etl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
